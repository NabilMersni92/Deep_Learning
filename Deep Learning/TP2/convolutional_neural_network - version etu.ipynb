{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3DR-eO17geWu"
   },
   "source": [
    "# Lab Assignment - Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3DR-eO17geWu"
   },
   "source": [
    "## In this lab activity, you will develop a convolutional neural network to classify photographs of dogs and cats.\n",
    "### The use of CNN model helps classifying the images into Dog or Cat classes while preserving their spatial structure. You will preprocess the images, create your CNN lodel, train it on the training set, and make predictions on a couple of observations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EMefrVPCg-60"
   },
   "source": [
    "### Importing the libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### If you did not download and install TensorFlow yet, using Anaconda, you can follow the following steps.\n",
    "\n",
    "#### On Windows open the Start menu and open an Anaconda Command Prompt. On macOS or Linux open a terminal window. Use the default bash shell on macOS or Linux.\n",
    "\n",
    "#### Choose a name for your TensorFlow environment, such as “tf”.\n",
    "\n",
    "#### To install the current release of CPU-only TensorFlow execute the following commands:\n",
    "     conda create -n tf tensorflow\n",
    "     conda activate tf\n",
    "\n",
    "\n",
    "#### You can install TensorFlow in the base (root) environment. To do so, you should activate your base environment first, and then install tensorflow by executing the following commands:\n",
    "    conda activate base # activate base environment \n",
    "    pip install tensorflow # install tensorflow (can be done via conda too, beware of cpu/gpu versions)\n",
    "    conda create -n tf tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sCV30xyVhFbE"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "# other needed packages are imported in the next steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FIleuCAjoFD8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.10.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__ #to print the version or uou tensorflow environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oxQxCBWyoGPE"
   },
   "source": [
    "## Part 1 - Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In this example, we work with images, so we do not have independent and dependant variables defined exiplicitly in a dataframe such as we usually have in the ML or DL case studies when we work with structured datasets.\n",
    "### To do the data proprocessing, we may have several solutions.\n",
    "### First solution consist of naming the dogs images using the term ‘dog’ and the cats images using the term ‘image. We can create an algorithm that extracts the label name dog or cat from the name of the image file to specify to the algorithm whether this image belongs to the class dog or the class cat.\n",
    "### Another solution can be implemented using Keras. We import images by preparing a spatial structure for our dataset. First, we need to separate the images into two folders training set and testing set. Then in each of these folders, we include two separate sub-folders named cats and dogs to differentiate the cat and dogs images, to help keras understand the labels of the dependent variables to differentiate them into the cat class and the dog class.\n",
    "### This is the first step to do in the preprocessing phase.\n",
    "### We do not need to encode data because the independent variables are pixels thus there are no categorical data.\n",
    "### As you recognize, in this case, the preprocessing part is done manually.\n",
    "### Do not forget that we need to apply feature scaling later, before we fit our CNN to our images.\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MvE-heJNo3GG"
   },
   "source": [
    "### Preprocessing the Training set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    #Because we do not have a huge amount of images, to get better prediction results,\n",
    "    #we will use ImageDataGenerator that is a method used to avoid overfitting using data augmentation\n",
    "    #It creates many batches of the images, and apply transformations on each batch on a random number of images such as rotating, flipping them...\n",
    "    #So we can get many more diversed images in our training set\n",
    "    #Read more about ImageDataGenerator() to understand how we are pre-processing our train and test sets below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0koUcJMJpEBD"
   },
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "training_set = train_datagen.flow_from_directory('dataset/training_set',\n",
    "                                                 target_size = (64, 64),\n",
    "                                                 batch_size = 32,\n",
    "                                                 class_mode = 'binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add your explanation of the previous block of code here "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mrCMmGw9pHys"
   },
   "source": [
    "### Preprocessing the Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SH4WzfOhpKc3"
   },
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "test_set = test_datagen.flow_from_directory('dataset/test_set',\n",
    "                                            target_size = (64, 64),\n",
    "                                            batch_size = 32,\n",
    "                                            class_mode = 'binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add your explanation of the previous block of code here "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "af8O4l90gk7B"
   },
   "source": [
    "## Part 2 - Building the CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ces1gXY2lmoX"
   },
   "source": [
    "### Initialising the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SAUt4UMPlhLS"
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential #to initialize our NN as a sequence of layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    #create and initialize a sequential model called classifierCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u5YJj_XMl5LF"
   },
   "source": [
    "### Step 1 - Convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XPzPrMckl-hV"
   },
   "outputs": [],
   "source": [
    "from keras.layers import Convolution2D #the package that we use to implement the convolution step to add the convolutional layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    #images are 2D, videos are 3D addint the time dimension\n",
    "    #since we are working with images, we use Convolution2D\n",
    "\n",
    "    #add the first convolutional layer\n",
    "    # use classifierCNN.add(Convolution2D(...[params]...))\n",
    "    # set the number of filter detectors to 32 of size 3x3, use filters and kernel_size params\n",
    "    # We usually start with 32 filter detectors and in the next layers we can use 64\n",
    "    #We need to convert all our images into an expected format our output image, we will use the param input_shape=[64, 64, 3] this means we are expecting 3 channels becauze we have colored images of size 64x64 pixels (we can use 256x256 if we have a GPU machine)\n",
    "    # Apply Rectifier activation function to eliminate the non-linearity by removing the negative values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tf87FpvxmNOJ"
   },
   "source": [
    "### Step 2 - Pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ncpqPl69mOac"
   },
   "outputs": [],
   "source": [
    "from keras.layers import MaxPooling2D #the package that we use add the pooling layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    # to reduce the size of the feature map, we generate a pooled feature map \n",
    "    # to do so, add a pooling layer\n",
    "    # use classifierCNN.add(MaxPooling2D(...[params]...))\n",
    "    # set the size to 2x2, recommended\n",
    "    # set strides to 2 which is the number of pixels shifts over the input matrix.\n",
    "    # the stride is a parameter that denotes the number of pixels the window moves by after each operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xaTOgD8rm4mU"
   },
   "source": [
    "### Adding a second convolutional and pooling layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "i_-FZjn_m8gk"
   },
   "source": [
    "    # repeat the same previous steps to add a second convolutional and pooling payers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tmiEuvTunKfk"
   },
   "source": [
    "### Step 3 - Flattening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6AZeOGCvnNZn"
   },
   "outputs": [],
   "source": [
    "from keras.layers import Flatten #the package that we use to convert the pooled feature maps into large feature vector to become the input of the fully connected layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    # use Flatten() to to convert the pooled feature maps into a flatten large feature vector\n",
    "    # create a classic ANN composed of some fully connected layers where the input layer is the flatten vector\n",
    "    # use add to add this flatten vector as an input layer to our classifierCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dAoSECOm203v"
   },
   "source": [
    "### Step 4 - Full Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8GtmUlLd26Nq"
   },
   "outputs": [],
   "source": [
    "from keras.layers import Dense #the package that we use to add the fully connected layers into a classic ANN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    # Add a new hidden layer to our classifierCNN\n",
    "    # start with 128 units \n",
    "    # consider applying the rectifier application function on the hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yTldFvbX28Na"
   },
   "source": [
    "### Step 5 - Output Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1p_Zj1Mc3Ko_"
   },
   "source": [
    "    # add the output layer with one expected binary output variable\n",
    "    # the binary output is the predicted category of one class (dog or cat)\n",
    "    # use the softmax activation function if you have a set of categorical variables as output\n",
    "    # use the sigmoid activation function when you have a binary output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "D6XkI90snSDl"
   },
   "source": [
    "## Part 3 - Training the CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vfrFQACEnc6i"
   },
   "source": [
    "### Compiling the CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NALksrNQpUlJ"
   },
   "source": [
    "    # the last step of the building of our CNN is to compile the model\n",
    "    # use compile() function\n",
    "    # apply adam algorithm using the optimizer param\n",
    "    # Note that Adam is an optimization algorithm that can be used instead of the classical stochastic gradient descent procedure to update network weights iterative based in training data.\n",
    "    # It is an extension to stochastic gradient descent that has recently seen broader adoption for deep learning applications in computer vision and natural language processing.\n",
    "    # Apply the crossentropy loss function\n",
    "    # we use binary_crossentropy when we have a binary output and categorical_crossentropy when the output is categorical\n",
    "    # use the accuracy metric as your performance metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ehS-v3MIpX2h"
   },
   "source": [
    "### Training the CNN on the Training set and evaluating it on the Test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    # fit the CNN model on your training data\n",
    "    # try with 25 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XUj1W4PJptta"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "250/250 [==============================] - 54s 201ms/step - loss: 0.6794 - accuracy: 0.5809 - val_loss: 0.6255 - val_accuracy: 0.6515\n",
      "Epoch 2/25\n",
      "250/250 [==============================] - 41s 164ms/step - loss: 0.6029 - accuracy: 0.6773 - val_loss: 0.5736 - val_accuracy: 0.7120\n",
      "Epoch 3/25\n",
      "250/250 [==============================] - 43s 172ms/step - loss: 0.5591 - accuracy: 0.7141 - val_loss: 0.5439 - val_accuracy: 0.7420\n",
      "Epoch 4/25\n",
      "250/250 [==============================] - 40s 161ms/step - loss: 0.5251 - accuracy: 0.7440 - val_loss: 0.5081 - val_accuracy: 0.7550\n",
      "Epoch 5/25\n",
      "250/250 [==============================] - 43s 173ms/step - loss: 0.5120 - accuracy: 0.7420 - val_loss: 0.5115 - val_accuracy: 0.7490\n",
      "Epoch 6/25\n",
      "250/250 [==============================] - 42s 169ms/step - loss: 0.4963 - accuracy: 0.7600 - val_loss: 0.5655 - val_accuracy: 0.7310\n",
      "Epoch 7/25\n",
      "250/250 [==============================] - 44s 174ms/step - loss: 0.4822 - accuracy: 0.7625 - val_loss: 0.4806 - val_accuracy: 0.7720\n",
      "Epoch 8/25\n",
      "250/250 [==============================] - 43s 173ms/step - loss: 0.4662 - accuracy: 0.7714 - val_loss: 0.5256 - val_accuracy: 0.7570\n",
      "Epoch 9/25\n",
      "250/250 [==============================] - 43s 171ms/step - loss: 0.4573 - accuracy: 0.7850 - val_loss: 0.4573 - val_accuracy: 0.7840\n",
      "Epoch 10/25\n",
      "250/250 [==============================] - 43s 173ms/step - loss: 0.4472 - accuracy: 0.7879 - val_loss: 0.4921 - val_accuracy: 0.7735\n",
      "Epoch 11/25\n",
      "250/250 [==============================] - 42s 169ms/step - loss: 0.4346 - accuracy: 0.7910 - val_loss: 0.4403 - val_accuracy: 0.7950\n",
      "Epoch 12/25\n",
      "250/250 [==============================] - 42s 169ms/step - loss: 0.4263 - accuracy: 0.7969 - val_loss: 0.4710 - val_accuracy: 0.7750\n",
      "Epoch 13/25\n",
      "250/250 [==============================] - 46s 184ms/step - loss: 0.4193 - accuracy: 0.8036 - val_loss: 0.4594 - val_accuracy: 0.7915\n",
      "Epoch 14/25\n",
      "250/250 [==============================] - 42s 166ms/step - loss: 0.4113 - accuracy: 0.8065 - val_loss: 0.4621 - val_accuracy: 0.7885\n",
      "Epoch 15/25\n",
      "250/250 [==============================] - 41s 166ms/step - loss: 0.3964 - accuracy: 0.8156 - val_loss: 0.4599 - val_accuracy: 0.7950\n",
      "Epoch 16/25\n",
      "250/250 [==============================] - 42s 170ms/step - loss: 0.3907 - accuracy: 0.8201 - val_loss: 0.4799 - val_accuracy: 0.7835\n",
      "Epoch 17/25\n",
      "250/250 [==============================] - 42s 166ms/step - loss: 0.3798 - accuracy: 0.8215 - val_loss: 0.4697 - val_accuracy: 0.7925\n",
      "Epoch 18/25\n",
      "250/250 [==============================] - 42s 169ms/step - loss: 0.3802 - accuracy: 0.8248 - val_loss: 0.4299 - val_accuracy: 0.8095\n",
      "Epoch 19/25\n",
      "250/250 [==============================] - 46s 184ms/step - loss: 0.3740 - accuracy: 0.8267 - val_loss: 0.4341 - val_accuracy: 0.8040\n",
      "Epoch 20/25\n",
      "250/250 [==============================] - 49s 195ms/step - loss: 0.3558 - accuracy: 0.8397 - val_loss: 0.4633 - val_accuracy: 0.7885\n",
      "Epoch 21/25\n",
      "250/250 [==============================] - 49s 197ms/step - loss: 0.3497 - accuracy: 0.8457 - val_loss: 0.4228 - val_accuracy: 0.8150\n",
      "Epoch 22/25\n",
      "250/250 [==============================] - 48s 191ms/step - loss: 0.3423 - accuracy: 0.8440 - val_loss: 0.4483 - val_accuracy: 0.7990\n",
      "Epoch 23/25\n",
      "250/250 [==============================] - 44s 176ms/step - loss: 0.3340 - accuracy: 0.8504 - val_loss: 0.4377 - val_accuracy: 0.8050\n",
      "Epoch 24/25\n",
      "250/250 [==============================] - 40s 158ms/step - loss: 0.3346 - accuracy: 0.8522 - val_loss: 0.4394 - val_accuracy: 0.8055\n",
      "Epoch 25/25\n",
      "250/250 [==============================] - 39s 158ms/step - loss: 0.3246 - accuracy: 0.8561 - val_loss: 0.4336 - val_accuracy: 0.8015\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x211c7252610>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "U3PZasO0006Z"
   },
   "source": [
    "## Part 4 - Making a single prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gsSiWEJY1BPB"
   },
   "source": [
    "    # Make a single prediction\n",
    "    # load your image, convert it to array, then predict its class using your CNN model\n",
    "    # print the predicted value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ED9KB3I54c1i"
   },
   "outputs": [],
   "source": [
    "# write your code here"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "convolutional_neural_network.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
